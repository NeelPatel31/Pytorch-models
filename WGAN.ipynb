{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhGscG+W6nzicrUk3CFwzc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"rsjtEGeKpY81","executionInfo":{"status":"ok","timestamp":1742120903928,"user_tz":-330,"elapsed":18571,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, channels_img, features_d):\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            # input: N x channels_img x 64 x 64\n","            nn.Conv2d(\n","                channels_img, features_d, kernel_size=4, stride=2, padding=1\n","            ),\n","            nn.LeakyReLU(0.2),\n","            # _block(in_channels, out_channels, kernel_size, stride, padding)\n","            self._block(features_d, features_d * 2, 4, 2, 1),\n","            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n","            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n","            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n","            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias=False,\n","            ),\n","            nn.InstanceNorm2d(out_channels, affine=True),\n","            nn.LeakyReLU(0.2),\n","        )\n","\n","    def forward(self, x):\n","        return self.disc(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, channels_noise, channels_img, features_g):\n","        super(Generator, self).__init__()\n","        self.net = nn.Sequential(\n","            # Input: N x channels_noise x 1 x 1\n","            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n","            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n","            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n","            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n","            nn.ConvTranspose2d(\n","                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n","            ),\n","            # Output: N x channels_img x 64 x 64\n","            nn.Tanh(),\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias=False,\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"],"metadata":{"id":"7BFd7gRMp1fP","executionInfo":{"status":"ok","timestamp":1742120903979,"user_tz":-330,"elapsed":7,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WI3mpP_xjmAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def initialize_weights(model):\n","    # Initializes weights according to the DCGAN paper\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def test():\n","    N, in_channels, H, W = 8, 3, 64, 64\n","    noise_dim = 100\n","    x = torch.randn((N, in_channels, H, W))\n","    disc = Discriminator(in_channels, 8)\n","    assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n","    gen = Generator(noise_dim, in_channels, 8)\n","    z = torch.randn((N, noise_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n","    print(\"Success, tests passed!\")\n","test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4B2PT_9Xp3tZ","executionInfo":{"status":"ok","timestamp":1742120904212,"user_tz":-330,"elapsed":226,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}},"outputId":"8834af59-5ed2-4d97-83d3-1e786e8828de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Success, tests passed!\n"]}]},{"cell_type":"code","source":["# Hyperparameters etc\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LEARNING_RATE = 5e-5\n","BATCH_SIZE = 64\n","IMAGE_SIZE = 64\n","CHANNELS_IMG = 1\n","Z_DIM = 100\n","NUM_EPOCHS = 5\n","FEATURES_CRITIC = 64\n","FEATURES_GEN = 64\n","CRITIC_ITERATIONS = 5\n","WEIGHT_CLIP = 0.01"],"metadata":{"id":"mbqTrVtmp5sb","executionInfo":{"status":"ok","timestamp":1742120915836,"user_tz":-330,"elapsed":5,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["transforms = transforms.Compose(\n","    [\n","        transforms.Resize(IMAGE_SIZE),\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n","        ),\n","    ]\n",")\n","\n","dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eGFek0hKqBL0","executionInfo":{"status":"ok","timestamp":1742120939229,"user_tz":-330,"elapsed":10501,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}},"outputId":"efc95b3b-2f8f-4123-bb0d-cf22eb976e31"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:02<00:00, 4.56MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n","100%|██████████| 1.65M/1.65M [00:01<00:00, 1.30MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 5.49MB/s]\n"]}]},{"cell_type":"code","source":["loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"kjrxbImwqEOU","executionInfo":{"status":"ok","timestamp":1742120939242,"user_tz":-330,"elapsed":7,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n","critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n","initialize_weights(gen)\n","initialize_weights(critic)"],"metadata":{"id":"5elTjoY_qHo1","executionInfo":{"status":"ok","timestamp":1742120942784,"user_tz":-330,"elapsed":252,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n","opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)"],"metadata":{"id":"BL_g5LmXqItf","executionInfo":{"status":"ok","timestamp":1742120943881,"user_tz":-330,"elapsed":18,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n","writer_real = SummaryWriter(f\"logs/real\")\n","writer_fake = SummaryWriter(f\"logs/fake\")\n","step = 0"],"metadata":{"id":"8kXX82i3qKAg","executionInfo":{"status":"ok","timestamp":1742120959240,"user_tz":-330,"elapsed":57,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["gen.train()\n","critic.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8maVR3wqLKk","executionInfo":{"status":"ok","timestamp":1742120978193,"user_tz":-330,"elapsed":34,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}},"outputId":"3e321ee6-6c46-42c1-cb9a-1fe1a91d37e6"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discriminator(\n","  (disc): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.2)\n","    (2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n","  )\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["for epoch in range(NUM_EPOCHS):\n","    # Target labels not needed! <3 unsupervised\n","    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n","        data = data.to(device)\n","        cur_batch_size = data.shape[0]\n","\n","        # Train Critic: max E[critic(real)] - E[critic(fake)]\n","        for _ in range(CRITIC_ITERATIONS):\n","            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n","            fake = gen(noise)\n","            critic_real = critic(data).reshape(-1)\n","            critic_fake = critic(fake).reshape(-1)\n","            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n","            critic.zero_grad()\n","            loss_critic.backward(retain_graph=True)\n","            opt_critic.step()\n","\n","            # clip critic weights between -0.01, 0.01\n","            for p in critic.parameters():\n","                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n","\n","        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n","        gen_fake = critic(fake).reshape(-1)\n","        loss_gen = -torch.mean(gen_fake)\n","        gen.zero_grad()\n","        loss_gen.backward()\n","        opt_gen.step()\n","\n","        # Print losses occasionally and print to tensorboard\n","        if batch_idx % 100 == 0 and batch_idx > 0:\n","            gen.eval()\n","            critic.eval()\n","            print(\n","                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n","                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n","            )\n","\n","            with torch.no_grad():\n","                fake = gen(noise)\n","                # take out (up to) 32 examples\n","                img_grid_real = torchvision.utils.make_grid(\n","                    data[:32], normalize=True\n","                )\n","                img_grid_fake = torchvision.utils.make_grid(\n","                    fake[:32], normalize=True\n","                )\n","\n","                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n","                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n","\n","            step += 1\n","            gen.train()\n","            critic.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"fewaY3TzqN0R","executionInfo":{"status":"error","timestamp":1742039825246,"user_tz":-330,"elapsed":79870,"user":{"displayName":"Neel D Patel","userId":"09865007007989319095"}},"outputId":"ce1f74e9-d67b-40a9-cdd9-66ec82c8eb08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 2/938 [01:19<10:17:27, 39.58s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-228db8c88069>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_real\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mopt_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["% tensorboard"],"metadata":{"id":"ouWK4rvRqQHL"},"execution_count":null,"outputs":[]}]}